{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12 Character Voiceover Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ffmpeg-python\n",
    "!ffmpeg -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Story\n",
    "import settings\n",
    "\n",
    "story = Story.load_from_directory(settings.STORY_DIR + \"/step_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import math\n",
    "import os\n",
    "\n",
    "def create_looped_video_with_voiceover(video_path, audio_path, output_path):\n",
    "    # Get video and audio durations\n",
    "    video_info = ffmpeg.probe(video_path)\n",
    "    audio_info = ffmpeg.probe(audio_path)\n",
    "    video_duration = float(video_info['streams'][0]['duration'])\n",
    "    audio_duration = float(audio_info['streams'][0]['duration'])\n",
    "    \n",
    "    # Calculate the number of loops required and create looped segments\n",
    "    loops_needed = math.ceil(audio_duration / video_duration)\n",
    "    segments = []\n",
    "    for i in range(loops_needed):\n",
    "        # Apply reverse filter on every alternate segment\n",
    "        segment = ffmpeg.input(video_path)\n",
    "        if i % 2 == 1:\n",
    "            segment = segment.filter('reverse')\n",
    "        segments.append(segment)\n",
    "\n",
    "    # Concatenate all segments to reach or exceed the audio duration\n",
    "    video = ffmpeg.concat(*segments, v=1, a=0)\n",
    "    video = video.trim(end=audio_duration)  # Trim excess duration\n",
    "\n",
    "    # Add the audio and export the final video\n",
    "    final_output = ffmpeg.output(video, ffmpeg.input(audio_path), output_path, vcodec='libx264', acodec='aac')\n",
    "    final_output.run(overwrite_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown, Video\n",
    "\n",
    "voiceover_dir = f\"{settings.STORY_DIR}/step_12/voiceover\"\n",
    "os.makedirs(voiceover_dir, exist_ok=True)\n",
    "character_videos = []\n",
    "\n",
    "for character in story.characters:\n",
    "    src_video_path = f\"{settings.STORY_DIR}/step_7/characters/{character.nickname}.mp4\"\n",
    "    # srce_audio_path = f\"{settings.STORY_DIR}/step_11/voices/{character.nickname}_catchphrase.wav\"\n",
    "    srce_audio_path = f\"{settings.STORY_DIR}/step_11/voices/{character.nickname}_catchphrase.fish.wav\"\n",
    "    dst_video_path = f\"{voiceover_dir}/{character.nickname}.mp4\"\n",
    "\n",
    "    create_looped_video_with_voiceover(src_video_path, srce_audio_path, dst_video_path)\n",
    "\n",
    "    character_videos.append(dst_video_path)\n",
    "\n",
    "    # Display character name and embedded video\n",
    "    display(Markdown(f\"### {character.name}\"))\n",
    "    display(Video(dst_video_path, embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_videos(video_paths, output_path):\n",
    "#     \"\"\"\n",
    "#     Combines multiple video files into one long video.\n",
    "\n",
    "#     Parameters:\n",
    "#     - video_paths: List of paths to video files to combine.\n",
    "#     - output_path: Path to save the combined output video.\n",
    "#     \"\"\"\n",
    "#     # Ensure there is at least one video to combine\n",
    "#     if not video_paths:\n",
    "#         raise ValueError(\"The video_paths list is empty.\")\n",
    "    \n",
    "#     # Create an input stream for each video and add to the inputs list\n",
    "#     inputs = [ffmpeg.input(video) for video in video_paths]\n",
    "    \n",
    "#     # Concatenate videos in sequence\n",
    "#     combined_video = ffmpeg.concat(*inputs, v=1, a=1)  # v=1 and a=1 mean we want to keep both video and audio\n",
    "\n",
    "#     # Output the final concatenated video\n",
    "#     final_output = ffmpeg.output(combined_video, output_path, vcodec='libx264', acodec='aac')\n",
    "#     final_output.run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "def combine_videos(video_paths, output_path):\n",
    "    \"\"\"\n",
    "    Combines multiple video files into one long video, ensuring each has an audio track.\n",
    "\n",
    "    Parameters:\n",
    "    - video_paths: List of paths to video files to combine.\n",
    "    - output_path: Path to save the combined output video.\n",
    "    \"\"\"\n",
    "    \n",
    "    def add_silent_audio(video_path):\n",
    "        # Create a temporary file with a silent audio track\n",
    "        temp_output = f\"{video_path}_with_audio.mp4\"\n",
    "        ffmpeg.input(video_path).output(\n",
    "            temp_output, vcodec='copy', acodec='aac', audio_bitrate='128k', anullsrc='1'\n",
    "        ).run(overwrite_output=True)\n",
    "        return temp_output\n",
    "    \n",
    "    # Ensure there is at least one video to combine\n",
    "    if not video_paths:\n",
    "        raise ValueError(\"The video_paths list is empty.\")\n",
    "    \n",
    "    # Process each video to ensure it has an audio track\n",
    "    processed_videos = []\n",
    "    for video in video_paths:\n",
    "        probe = ffmpeg.probe(video)\n",
    "        has_audio = any(stream['codec_type'] == 'audio' for stream in probe['streams'])\n",
    "        if not has_audio:\n",
    "            # Add silent audio if the video has no audio track\n",
    "            video_with_audio = add_silent_audio(video)\n",
    "            processed_videos.append(video_with_audio)\n",
    "        else:\n",
    "            processed_videos.append(video)\n",
    "    \n",
    "    # Create an input stream for each processed video\n",
    "    inputs = [ffmpeg.input(video) for video in processed_videos]\n",
    "    \n",
    "    # Concatenate videos in sequence\n",
    "    combined_video = ffmpeg.concat(*[i.video for i in inputs], v=1, a=0)\n",
    "    audio_concat = ffmpeg.concat(*[i.audio for i in inputs], v=0, a=1)\n",
    "    \n",
    "    # Output the final concatenated video\n",
    "    final_output = ffmpeg.output(combined_video, audio_concat, output_path, vcodec='libx264', acodec='aac')\n",
    "    final_output.run(overwrite_output=True)\n",
    "    \n",
    "    # Clean up any temporary files created\n",
    "    for temp_file in processed_videos:\n",
    "        if temp_file.endswith(\"_with_audio.mp4\") and os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_dir = f\"{settings.STORY_DIR}/step_12/voiceover\"\n",
    "output_path = f\"{settings.STORY_DIR}/step_12/combined_video.mp4\"\n",
    "combine_videos(character_videos, output_path)\n",
    "\n",
    "display(Video(output_path))\n",
    "display(Video(output_path, embed=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotomatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
