{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12 Character Voiceover Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ffmpeg-python in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from ffmpeg-python) (1.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "libavutil      56. 70.100 / 56. 70.100\n",
      "libavcodec     58.134.100 / 58.134.100\n",
      "libavformat    58. 76.100 / 58. 76.100\n",
      "libavdevice    58. 13.100 / 58. 13.100\n",
      "libavfilter     7.110.100 /  7.110.100\n",
      "libswscale      5.  9.100 /  5.  9.100\n",
      "libswresample   3.  9.100 /  3.  9.100\n",
      "libpostproc    55.  9.100 / 55.  9.100\n"
     ]
    }
   ],
   "source": [
    "%pip install ffmpeg-python\n",
    "!ffmpeg -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Story\n",
    "import settings\n",
    "\n",
    "story = Story.load_from_directory(settings.STORY_DIR + \"/step_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import math\n",
    "import os\n",
    "\n",
    "def create_looped_video_with_voiceover(video_path, audio_path, output_path):\n",
    "    # Get video and audio durations\n",
    "    video_info = ffmpeg.probe(video_path)\n",
    "    audio_info = ffmpeg.probe(audio_path)\n",
    "    video_duration = float(video_info['streams'][0]['duration'])\n",
    "    audio_duration = float(audio_info['streams'][0]['duration'])\n",
    "    \n",
    "    # Calculate the number of loops required and create looped segments\n",
    "    loops_needed = math.ceil(audio_duration / video_duration)\n",
    "    segments = []\n",
    "    for i in range(loops_needed):\n",
    "        # Apply reverse filter on every alternate segment\n",
    "        segment = ffmpeg.input(video_path)\n",
    "        if i % 2 == 1:\n",
    "            segment = segment.filter('reverse')\n",
    "        segments.append(segment)\n",
    "\n",
    "    # Concatenate all segments to reach or exceed the audio duration\n",
    "    video = ffmpeg.concat(*segments, v=1, a=0)\n",
    "    video = video.trim(end=audio_duration)  # Trim excess duration\n",
    "\n",
    "    # Add the audio and export the final video\n",
    "    final_output = ffmpeg.output(video, ffmpeg.input(audio_path), output_path, vcodec='libx264', acodec='aac')\n",
    "    final_output.run(overwrite_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "ffprobe error (see stderr output for detail)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m src_audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msettings\u001b[38;5;241m.\u001b[39mSTORY_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/step_11/voices/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcharacter\u001b[38;5;241m.\u001b[39mnickname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_catchphrase.fish.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m dst_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvoiceover_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcharacter\u001b[38;5;241m.\u001b[39mnickname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mcreate_looped_video_with_voiceover\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_video_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m character_videos\u001b[38;5;241m.\u001b[39mappend(dst_video_path)\n\u001b[1;32m     18\u001b[0m character_gifs\u001b[38;5;241m.\u001b[39mappend(src_gif_path)\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mcreate_looped_video_with_voiceover\u001b[0;34m(video_path, audio_path, output_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_looped_video_with_voiceover\u001b[39m(video_path, audio_path, output_path):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Get video and audio durations\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     video_info \u001b[38;5;241m=\u001b[39m ffmpeg\u001b[38;5;241m.\u001b[39mprobe(video_path)\n\u001b[0;32m----> 8\u001b[0m     audio_info \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     video_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(video_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     audio_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(audio_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/plotomatic/lib/python3.12/site-packages/ffmpeg/_probe.py:23\u001b[0m, in \u001b[0;36mprobe\u001b[0;34m(filename, cmd, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m out, err \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffprobe\u001b[39m\u001b[38;5;124m'\u001b[39m, out, err)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(out\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mError\u001b[0m: ffprobe error (see stderr output for detail)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown, Video\n",
    "\n",
    "voiceover_dir = f\"{settings.STORY_DIR}/step_12/voiceover\"\n",
    "os.makedirs(voiceover_dir, exist_ok=True)\n",
    "character_videos = []\n",
    "character_gifs = []\n",
    "\n",
    "for character in story.characters:\n",
    "    src_video_path = f\"{settings.STORY_DIR}/step_7/characters/{character.nickname}.mp4\"\n",
    "    src_gif_path = f\"{settings.STORY_DIR}/step_7/characters/{character.nickname}.gif\"\n",
    "    src_audio_path = f\"{settings.STORY_DIR}/step_11/voices/{character.nickname}_catchphrase.fish.wav\"\n",
    "    dst_video_path = f\"{voiceover_dir}/{character.nickname}.mp4\"\n",
    "\n",
    "    create_looped_video_with_voiceover(src_video_path, src_audio_path, dst_video_path)\n",
    "\n",
    "    character_videos.append(dst_video_path)\n",
    "    character_gifs.append(src_gif_path)\n",
    "\n",
    "    # Display character name and embedded video\n",
    "    display(Markdown(f\"### {character.name}\"))\n",
    "    display(Video(dst_video_path, embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "def combine_videos(video_paths, output_path):\n",
    "    \"\"\"\n",
    "    Combines multiple video files into one long video, ensuring each has an audio track.\n",
    "\n",
    "    Parameters:\n",
    "    - video_paths: List of paths to video files to combine.\n",
    "    - output_path: Path to save the combined output video.\n",
    "    \"\"\"\n",
    "    \n",
    "    def add_silent_audio(video_path):\n",
    "        # Create a temporary file with a silent audio track\n",
    "        temp_output = f\"{video_path}_with_audio.mp4\"\n",
    "        ffmpeg.input(video_path).output(\n",
    "            temp_output, vcodec='copy', acodec='aac', audio_bitrate='128k', anullsrc='1'\n",
    "        ).run(overwrite_output=True)\n",
    "        return temp_output\n",
    "    \n",
    "    # Ensure there is at least one video to combine\n",
    "    if not video_paths:\n",
    "        raise ValueError(\"The video_paths list is empty.\")\n",
    "    \n",
    "    # Process each video to ensure it has an audio track\n",
    "    processed_videos = []\n",
    "    for video in video_paths:\n",
    "        probe = ffmpeg.probe(video)\n",
    "        has_audio = any(stream['codec_type'] == 'audio' for stream in probe['streams'])\n",
    "        if not has_audio:\n",
    "            # Add silent audio if the video has no audio track\n",
    "            video_with_audio = add_silent_audio(video)\n",
    "            processed_videos.append(video_with_audio)\n",
    "        else:\n",
    "            processed_videos.append(video)\n",
    "    \n",
    "    # Create an input stream for each processed video\n",
    "    inputs = [ffmpeg.input(video) for video in processed_videos]\n",
    "    \n",
    "    # Concatenate videos in sequence\n",
    "    combined_video = ffmpeg.concat(*[i.video for i in inputs], v=1, a=0)\n",
    "    audio_concat = ffmpeg.concat(*[i.audio for i in inputs], v=0, a=1)\n",
    "    \n",
    "    # Output the final concatenated video\n",
    "    final_output = ffmpeg.output(combined_video, audio_concat, output_path, vcodec='libx264', acodec='aac')\n",
    "    final_output.run(overwrite_output=True)\n",
    "    \n",
    "    # Clean up any temporary files created\n",
    "    for temp_file in processed_videos:\n",
    "        if temp_file.endswith(\"_with_audio.mp4\") and os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def combine_gifs(gif_paths, output_path):\n",
    "    \"\"\"\n",
    "    Combines multiple GIF files into one long GIF.\n",
    "\n",
    "    Parameters:\n",
    "    - gif_paths: List of paths to GIF files to combine.\n",
    "    - output_path: Path to save the combined output GIF.\n",
    "    \"\"\"\n",
    "    # Open all GIFs and extract frames\n",
    "    frames = []\n",
    "    for gif_path in gif_paths:\n",
    "        gif = Image.open(gif_path)\n",
    "        frames.extend([frame.copy() for frame in ImageSequence.Iterator(gif)])\n",
    "\n",
    "    # Save frames as a single GIF\n",
    "    frames[0].save(output_path, save_all=True, append_images=frames[1:], loop=0, duration=frames[0].info['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the combined video\n",
    "\n",
    "from IPython.display import display, Markdown, Video, IPImage\n",
    "\n",
    "gif_output_path = f\"{settings.STORY_DIR}/step_12/combined_video.gif\"\n",
    "combine_gifs(character_videos, gif_output_path)\n",
    "display(IPImage(filename=gif_output_path))\n",
    "\n",
    "output_path = f\"{settings.STORY_DIR}/step_12/combined_video.mp4\"\n",
    "combine_videos(character_videos, output_path)\n",
    "display(Video(output_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotomatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
