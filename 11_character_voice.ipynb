{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Voice\n",
    "This is a bonus. Let's try to give these characters a voice.\n",
    "\n",
    "TODO: Do the cloning in a separate env to avoid pypi conflicts.\n",
    "\n",
    "## Generate new voice\n",
    "First we will use [Parler-TTS](https://huggingface.co/parler-tts/parler-tts-large-v1) to generate a new voice for each character by inputting a description of the voice heard. We save that voice to a wav file for reference.\n",
    "\n",
    "## Voice Cloning\n",
    "Then for anything we want a character to say, we use [CoquiTTS](https://huggingface.co/coqui/XTTS-v2) to clone that voice and generate new speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "from model import Story, Character\n",
    "\n",
    "story = Story.load_from_directory(settings.STORY_DIR + \"/step_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parler lets us create a voice with a description of how it sounds\n",
    "%pip install transformers==4.21.1 \n",
    "# As of 11/2/2024 this breaks (audio is garbled)\n",
    "%pip install --upgrade git+https://github.com/huggingface/parler-tts.git@dcaed95e1cce6f616e3e1956f8d63f0f3f5dfe5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Let's create the directory we will store reference voices in\n",
    "current_step = 11\n",
    "wav_file_dir = f\"{settings.STORY_DIR}/step_{current_step}/voices/\"\n",
    "os.makedirs(wav_file_dir, exist_ok=True)\n",
    "\n",
    "def speech_path(character):\n",
    "    return f\"{wav_file_dir}/{character.name}.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Reference Speech\n",
    "\n",
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"parler-tts/parler-tts-large-v1\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_speech(character: Character):\n",
    "    description = f\"very clear audio of a {character.gender} {character.race} age around {character.age} {character.voice_description}\"\n",
    "    baseline_speech = \"The birch canoe slid on the smooth planks. Glue the sheet to the dark blue background. These days a chicken leg is a rare dish. Rice is often served in round bowls. Help the woman get back to her feet.\"\n",
    "\n",
    "    display(description)\n",
    "\n",
    "    input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_input_ids = tokenizer(baseline_speech, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "    audio_arr = generation.cpu().numpy().squeeze()\n",
    "\n",
    "    # Save the wave file\n",
    "    wave_file = speech_path(character)\n",
    "    sf.write(wave_file, audio_arr, model.config.sampling_rate)\n",
    "\n",
    "    # Might be able to do this to fix the attention mask: https://www.reddit.com/r/KoboldAI/comments/yz26ol/how_to_fix_the_attention_mask_and_the_pad_token/\n",
    "    \n",
    "    return wave_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_baseline_speech(character: Character, prompt: str):\n",
    "#     description = f\"A {character.gender} age around {character.age} with a voice like: {character.voice_description}\"\n",
    "#     baseline_speech = \"The birch canoe slid on the smooth planks. Glue the sheet to the dark blue background. These days a chicken leg is a rare dish. Rice is often served in round bowls. Help the woman get back to her feet.\"\n",
    "\n",
    "#     display(description)\n",
    "\n",
    "#     input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "#     prompt_input_ids = tokenizer(baseline_speech, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "#     generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "#     audio_arr = generation.cpu().numpy().squeeze()\n",
    "    \n",
    "#     # Save the wave file\n",
    "#     wave_file = speech_path(character)\n",
    "#     sf.write(wave_file, audio_arr, model.config.sampling_rate)\n",
    "    \n",
    "#     return wave_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Baseline for Each Character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "for character in story.characters:\n",
    "    display(Markdown(f\"\"\"---\n",
    "## {character.name}\n",
    "**Voice**: {character.voice_description}\n",
    "\"\"\"))\n",
    "    display(ipd.Audio(create_baseline_speech(character)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone Voice (Fish Speech)\n",
    "\n",
    "## Install fish-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fishaudio/fish-speech.git || echo Already Cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n",
    "\n",
    "# (Ubuntu / Debian User) Install sox + ffmpeg\n",
    "# !sudo apt install -y libsox-dev ffmpeg \n",
    "\n",
    "# (Ubuntu / Debian User) Install pyaudio \n",
    "# !sudo apt install build-essential cmake libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
    "    \n",
    "# Install fish-speech\n",
    "%pip install -e ./fish-speech[stable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download fishaudio/fish-speech-1.4 --local-dir fish-speech/checkpoints/fish-speech-1.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "from model import Story, Character\n",
    "\n",
    "story = Story.load_from_directory(settings.STORY_DIR + \"/step_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Let's create the directory we will store reference voices in\n",
    "current_step = 11\n",
    "wav_file_dir = f\"{settings.STORY_DIR}/step_{current_step}/voices/\"\n",
    "os.makedirs(wav_file_dir, exist_ok=True)\n",
    "\n",
    "def baseline_wav(character: Character) -> str:\n",
    "    return f\"{wav_file_dir}/{character.name}.wav\"\n",
    "\n",
    "def baseline_npy(character: Character) -> str:\n",
    "    return f\"{wav_file_dir}/{character.name}.fish.npy\"\n",
    "\n",
    "def catchphrase_fish(character: Character):\n",
    "    return f\"{wav_file_dir}/{character.name}.catchphrase.fish.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Baseline Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in story.characters:\n",
    "    src_audio = baseline_wav(character)\n",
    "    dst_audio = baseline_npy(character)\n",
    "    !python fish-speech/tools/vqgan/inference.py \\\n",
    "        -i \"{src_audio}\" \\\n",
    "        -o \"{dst_audio}\" \\\n",
    "        --checkpoint-path \"fish-speech/checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Catchphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "baseline_speech = \"The birch canoe slid on the smooth planks. Glue the sheet to the dark blue background. These days a chicken leg is a rare dish. Rice is often served in round bowls. Help the woman get back to her feet.\"\n",
    "\n",
    "for character in story.characters:\n",
    "    display(Markdown(f\"\"\"---\n",
    "\n",
    "## {character.name}\n",
    "\n",
    "**Gender**: {character.gender}\n",
    "\n",
    "**Age**: {character.age}\n",
    "\n",
    "**Voice**: {character.voice_description}\n",
    "\n",
    "**Catch Phrase**: {character.catch_phrase}\n",
    "\"\"\"))\n",
    "    # display(character.image)\n",
    "    image_path = f\"{settings.STORY_DIR}/step_7/characters/{character.name}.gif\"\n",
    "    display(IPImage(image_path))\n",
    "\n",
    "    reference_file = baseline_wav(character)\n",
    "    output_file = catchphrase_fish(character)\n",
    "    npy = baseline_npy(character)\n",
    "    text = f\"I'm {character.name}. {character.description}. {character.catch_phrase}\"\n",
    "\n",
    "    # Generate tokens\n",
    "    !python fish-speech/tools/llama/generate.py \\\n",
    "        --text \"{text}\" \\\n",
    "        --prompt-text \"{baseline_speech}\" \\\n",
    "        --prompt-tokens \"{npy}\" \\\n",
    "        --checkpoint-path \"fish-speech/checkpoints/fish-speech-1.4\" \\\n",
    "        --num-samples 2 \\\n",
    "        --compile \\\n",
    "        --device cuda\n",
    "\n",
    "    # Inference\n",
    "    !python fish-speech/tools/vqgan/inference.py \\\n",
    "        -i \"codes_0.npy\" \\\n",
    "        -o \"{output_file}\" \\\n",
    "        --checkpoint-path \"fish-speech/checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\\\n",
    "        --device cuda\n",
    "\n",
    "\n",
    "    display(\"Reference file\")\n",
    "    display(ipd.Audio(reference_file))\n",
    "    \n",
    "    display(\"Catch Phrase\")\n",
    "    display(ipd.Audio(output_file))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Voice (CoquiTTS)\n",
    "\n",
    "Let's generate each character catch-phrase based off the previous baseline voice.\n",
    "\n",
    "### NOTE: THIS BREAKS THE ABOVE VOICE CLONING DUE TO TRANSFORMERS VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoquiTTS will let us clone that previously generated voice and replicate it for new TTS\n",
    "# %pip install TTS # Doesn't work for Python 3.12.7\n",
    "%pip install --upgrade coqui-tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Voice\n",
    "\n",
    "Let's generate each character catch-phrase based off the previous baseline voice.\n",
    "\n",
    "### Load model\n",
    "\n",
    "## ALERT: YOU NEED TO RUN THIS IN THE TERMINAL FIRST TO AGREE TO THE LICENSE AGREEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "from model import Story, Character\n",
    "\n",
    "story = Story.load_from_directory(settings.STORY_DIR + \"/step_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Let's create the directory we will store reference voices in\n",
    "current_step = 11\n",
    "wav_file_dir = f\"{settings.STORY_DIR}/step_{current_step}/voices/\"\n",
    "os.makedirs(wav_file_dir, exist_ok=True)\n",
    "\n",
    "def speech_path(character):\n",
    "    return f\"{wav_file_dir}/{character.name}.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_path_catchphrase(character):\n",
    "    return f\"{wav_file_dir}/{character.name}.catchphrase.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "for character in story.characters:\n",
    "    display(Markdown(f\"\"\"---\n",
    "\n",
    "## {character.name}\n",
    "\n",
    "**Gender**: {character.gender}\n",
    "\n",
    "**Age**: {character.age}\n",
    "\n",
    "**Voice**: {character.voice_description}\n",
    "\n",
    "**Catch Phrase**: {character.catch_phrase}\n",
    "\"\"\"))\n",
    "    # display(character.image)\n",
    "    image_path = f\"{settings.STORY_DIR}/step_7/characters/{character.name}.gif\"\n",
    "    display(IPImage(image_path))\n",
    "\n",
    "    reference_file = wave_file = speech_path(character)\n",
    "    output_file = speech_path_catchphrase(character)\n",
    "\n",
    "    display(\"Reference file\")\n",
    "    display(ipd.Audio(reference_file))\n",
    "    \n",
    "    display(\"Catch Phrase\")\n",
    "    text = f\"I'm {character.name}. {character.description}. {character.catch_phrase}\"\n",
    "    tts.tts_to_file(text=text, speaker_wav=reference_file, language=\"en\", file_path=output_file)\n",
    "    display(ipd.Audio(output_file))\n",
    "\n",
    "    display(\"A quick brown fox jumps over the lazy dog.\")\n",
    "    wav = tts.tts(text=\"A quick brown fox jumps over the lazy dog.\", speaker_wav=reference_file, language=\"en\")\n",
    "    display(ipd.Audio(wav, rate=22050))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "for character in story.characters:\n",
    "    display(Markdown(f\"\"\"---\n",
    "\n",
    "## {character.name}\n",
    "\n",
    "**Gender**: {character.gender}\n",
    "\n",
    "**Age**: {character.age}\n",
    "\n",
    "**Voice**: {character.voice_description}\n",
    "\n",
    "**Catch Phrase**: {character.catch_phrase}\n",
    "\"\"\"))\n",
    "    # display(character.image)\n",
    "    image_path = f\"{settings.STORY_DIR}/step_7/characters/{character.name}.gif\"\n",
    "    display(IPImage(image_path))\n",
    "\n",
    "    reference_file = wave_file = speech_path(character)\n",
    "    output_file = speech_path_catchphrase(character)\n",
    "\n",
    "    display(\"Reference file\")\n",
    "    display(ipd.Audio(reference_file))\n",
    "    \n",
    "    display(\"Catch Phrase\")\n",
    "    text = f\"I'm {character.name}. {character.description}. {character.catch_phrase}\"\n",
    "    tts.tts_to_file(text=text, speaker_wav=reference_file, language=\"en\", file_path=output_file)\n",
    "    display(ipd.Audio(output_file))\n",
    "\n",
    "    display(\"A quick brown fox jumps over the lazy dog.\")\n",
    "    wav = tts.tts(text=\"A quick brown fox jumps over the lazy dog.\", speaker_wav=reference_file, language=\"en\")\n",
    "    display(ipd.Audio(wav, rate=22050))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotomatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
