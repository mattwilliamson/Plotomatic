{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "**Tested on Ubuntu 22.04**\n",
    "Using vscode and remote ssh extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "\n",
    "## Install Linux \n",
    "\n",
    "[Ollama Linux installation instructions](https://ollama.com/download/linux)\n",
    "\n",
    "```sh\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "## Try it\n",
    "\n",
    "```sh\n",
    "ollama list\n",
    "ollama pull llama3.1:70b\n",
    "ollama run llama3.1:70b\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your virtualenv with conda\n",
    "\n",
    "```sh\n",
    "conda create -n plotomatic python=3.12\n",
    "conda activate plotomatic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove conda packages (if there are issues)\n",
    "If you see this error, there is a bug with nvidia and conda where you will probably need to remove al of the conda packages using `conda remove` with the same args to to uninstall them, then reinstall them after. I have seen this if I try to install a new VSCode extension, too.\n",
    "\n",
    "```InvalidSpec: The package \"nvidia/linux-64::cuda-compiler==12.6.2=0\" is not available for the specified platform```\n",
    "\n",
    "```sh\n",
    "# One of these breaks conda for new install (probably cuda), so remove them first before adding new packages\n",
    "conda remove \\\n",
    "        cuda cuda-nvcc cuda-cudart cuda-compiler \\\n",
    "        pytorch-cuda pytorch torchvision \\\n",
    "        tensorflow-gpu tensorflow cudnn \\\n",
    "        ipykernel sqlite nbconvert\n",
    "```\n",
    "\n",
    "## Install conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipykernel is for vscode\n",
    "# %conda install \\\n",
    "#         cuda cuda-nvcc cuda-cudart cuda-compiler \\\n",
    "#         pytorch-cuda pytorch torchvision \\\n",
    "#         tensorflow-gpu tensorflow cudnn \\\n",
    "#         ipykernel sqlite nbconvert\n",
    "\n",
    "# Restart the Juptyer Notebook kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuda, TensorRT\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#install\n",
    "\n",
    "Skip the following if you aren't using CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if nvidia drivers and cuda are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Version: 12.4\n",
    "# Driver Version: 550.107.02\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install NVIDIA drivers\n",
    "\n",
    "Only do this if `nvidia-smi` didn't work.\n",
    "\n",
    "```sh\n",
    "sudo ubuntu-drivers devices | grep recommended\n",
    "sudo apt-get install nvidia-driver-550\n",
    "sudo reboot\n",
    "```\n",
    "\n",
    "### Check the driver is installed and working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt list --installed | grep nvidia-driver\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install CUDA\n",
    "```sh\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb\n",
    "sudo dpkg -i cuda-keyring_1.1-1_all.deb\n",
    "sudo apt-get update\n",
    "sudo apt-get -y install cuda-toolkit-12-4\n",
    "sudo apt-get install -y cuda-drivers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure TensorRT is installed\n",
    "\n",
    "!dpkg-query -W tensorrt \n",
    "# 10.5.0.18-1+cuda12.6\n",
    "\n",
    "!dpkg-query -W cuda-toolkit\n",
    "# 12.6.1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (24.3.1)\n",
      "Requirement already satisfied: wheel in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.44.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (75.3.0)\n",
      "Downloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.44.0\n",
      "    Uninstalling wheel-0.44.0:\n",
      "      Successfully uninstalled wheel-0.44.0\n",
      "Successfully installed wheel-0.45.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ninja in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (1.11.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip wheel setuptools \n",
    "\n",
    "# Ninja will help some packages compile faster\n",
    "%pip install ninja \n",
    "\n",
    "# These need to be installed first\n",
    "%pip install \\\n",
    "    nvidia-tensorrt \\\n",
    "    tensorflow \\\n",
    "    torch \\\n",
    "    tensorflow>=2.17.0 \\\n",
    "    cuda-python>=12.6.0 \\\n",
    "    torchvision>=0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 20:36:04.162636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-10 20:36:04.239692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731288964.269251  722948 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731288964.278070  722948 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 20:36:04.349235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0.dev20241107+cu121\n",
      "CUDA available: True\n",
      "Number of CUDA devices: 2\n",
      "Device 0: NVIDIA GeForce RTX 4090\n",
      "Device 1: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# Make sure they work\n",
    "import tensorrt\n",
    "import tensorflow\n",
    "import cuda\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \\\n",
    "    huggingface_hub \\\n",
    "    transformers>=4.25.1 \\\n",
    "    diffusers \\\n",
    "    accelerate \\\n",
    "    ipywidgets \\\n",
    "    matplotlib \\\n",
    "    sentencepiece \\\n",
    "    numpy \\\n",
    "    rembg[GPU] \\\n",
    "    pydantic \\\n",
    "    unidecode \\\n",
    "    deepdiff \\\n",
    "    json-repair \\\n",
    "    ollama \\\n",
    "    graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index-llms-ollama in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.3.4)\n",
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.3.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama_index in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.11.20)\n",
      "Collecting llama_index\n",
      "  Downloading llama_index-0.11.22-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-llms-ollama) (0.11.20)\n",
      "Requirement already satisfied: ollama>=0.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-llms-ollama) (0.3.3)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.3.1)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-llms-ollama)\n",
      "  Downloading llama_index_core-0.11.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.53.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index) (0.1.4)\n",
      "Requirement already satisfied: pandas in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama_index) (0.5.12)\n",
      "Requirement already satisfied: click in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nltk>3.8.1->llama_index) (2023.12.25)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.6)\n",
      "Requirement already satisfied: anyio in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.2.0)\n",
      "Downloading llama_index_llms_ollama-0.3.6-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index-0.11.22-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.11.22-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llama-index-core, llama-index-llms-ollama, llama_index\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.20\n",
      "    Uninstalling llama-index-core-0.11.20:\n",
      "      Successfully uninstalled llama-index-core-0.11.20\n",
      "  Attempting uninstall: llama-index-llms-ollama\n",
      "    Found existing installation: llama-index-llms-ollama 0.3.4\n",
      "    Uninstalling llama-index-llms-ollama-0.3.4:\n",
      "      Successfully uninstalled llama-index-llms-ollama-0.3.4\n",
      "  Attempting uninstall: llama_index\n",
      "    Found existing installation: llama-index 0.11.20\n",
      "    Uninstalling llama-index-0.11.20:\n",
      "      Successfully uninstalled llama-index-0.11.20\n",
      "Successfully installed llama-index-core-0.11.22 llama-index-llms-ollama-0.3.6 llama_index-0.11.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# llamaindex\n",
    "%pip install --upgrade llama-index-llms-ollama llama_index llama-index-embeddings-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nemoguardrails in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.10.1)\n",
      "Requirement already satisfied: llama-index-output-parsers-guardrails in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: aiohttp>=3.9.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (3.10.10)\n",
      "Requirement already satisfied: annoy>=1.17.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (1.17.3)\n",
      "Requirement already satisfied: fastapi>=0.103.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.115.4)\n",
      "Requirement already satisfied: fastembed>=0.2.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.27.2)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (3.1.4)\n",
      "Requirement already satisfied: langchain!=0.1.9,<0.3.0,>=0.2.14 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.2.17)\n",
      "Requirement already satisfied: langchain-core!=0.1.26,<0.3.0,>=0.2.14 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.2.43)\n",
      "Requirement already satisfied: langchain-community<0.3.0,>=0.0.16 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.2.18)\n",
      "Requirement already satisfied: lark~=1.1.7 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (1.1.9)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.6 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (1.6.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (3.0.48)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (2.9.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (6.0.2)\n",
      "Requirement already satisfied: rich>=13.5.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (13.9.3)\n",
      "Requirement already satisfied: simpleeval>=0.9.13 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (1.0.3)\n",
      "Requirement already satisfied: starlette>=0.27.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.41.2)\n",
      "Requirement already satisfied: typer>=0.7.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.9.4)\n",
      "Requirement already satisfied: uvicorn>=0.23 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (0.32.0)\n",
      "Requirement already satisfied: watchdog>=3.0.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nemoguardrails) (6.0.0)\n",
      "Requirement already satisfied: guardrails-ai<0.5.0,>=0.4.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-output-parsers-guardrails) (0.4.5)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-output-parsers-guardrails) (0.11.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastapi>=0.103.0->nemoguardrails) (4.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.26.2)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.7.2)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (4.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.26.4)\n",
      "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.19.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (10.4.0)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.1.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.20.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from fastembed>=0.2.2->nemoguardrails) (4.66.6)\n",
      "Requirement already satisfied: coloredlogs<16.0.0,>=15.0.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (15.0.1)\n",
      "Requirement already satisfied: griffe<0.37.0,>=0.36.9 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.36.9)\n",
      "Requirement already satisfied: guardrails-api-client<0.3.0,>=0.2.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.2.1)\n",
      "Requirement already satisfied: jwt<2.0.0,>=1.3.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.3.1)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (4.9.4)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (3.9.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.30.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.53.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.24.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: pip>=22 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (24.3.1)\n",
      "Requirement already satisfied: pydash<8.0.0,>=7.0.6 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (7.0.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (2.9.0)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.10.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (2023.12.25)\n",
      "Requirement already satisfied: rstr<4.0.0,>=3.2.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (3.2.2)\n",
      "Requirement already satisfied: tenacity>=8.1.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.8.0)\n",
      "Requirement already satisfied: anyio in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx>=0.24.1->nemoguardrails) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx>=0.24.1->nemoguardrails) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx>=0.24.1->nemoguardrails) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx>=0.24.1->nemoguardrails) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpx>=0.24.1->nemoguardrails) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->nemoguardrails) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from jinja2>=3.1.4->nemoguardrails) (2.1.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (2.0.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (0.1.142)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.0.16->nemoguardrails) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (24.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (2024.2.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (3.4.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from prompt-toolkit>=3.0->nemoguardrails) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pydantic>=1.10->nemoguardrails) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from pydantic>=1.10->nemoguardrails) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from rich>=13.5.2->nemoguardrails) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from rich>=13.5.2->nemoguardrails) (2.18.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from typer>=0.7.0->nemoguardrails) (8.1.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from coloredlogs<16.0.0,>=15.0.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.0.16->nemoguardrails) (3.23.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from griffe<0.37.0,>=0.36.9->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.4.6)\n",
      "Requirement already satisfied: filelock in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->nemoguardrails) (3.16.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (3.0.0)\n",
      "Requirement already satisfied: cryptography!=3.4.0,>=3.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from jwt<2.0.0,>=1.3.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (43.0.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nemoguardrails) (0.1.2)\n",
      "Requirement already satisfied: joblib in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.4.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from onnx<2.0.0,>=1.15.0->fastembed>=0.2.2->nemoguardrails) (5.28.3)\n",
      "Requirement already satisfied: flatbuffers in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (24.3.25)\n",
      "Requirement already satisfied: sympy in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.67.1)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (0.49b1)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (8.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->nemoguardrails) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->nemoguardrails) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (3.1.1)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from typer[all]<0.10.0,>=0.9.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-output-parsers-guardrails) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp>=3.9.2->nemoguardrails) (0.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from cryptography!=3.4.0,>=3.1->jwt<2.0.0,>=1.3.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (1.17.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from cffi>=1.12->cryptography!=3.4.0,>=3.1->jwt<2.0.0,>=1.3.1->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (2.22)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai<0.5.0,>=0.4.1->llama-index-output-parsers-guardrails) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# NVIDIA NeMo Guardrails\n",
    "%pip install --upgrade nemoguardrails llama-index-output-parsers-guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cogvideo\n",
    "# TODO: Move this to a separate notebook\n",
    "# https://huggingface.co/THUDM/CogVideoX-5b-I2V\n",
    "# %pip install --upgrade transformers accelerate diffusers imageio-ffmpeg tbb xfuser[flash_attn] onediff\n",
    "\n",
    "# xfuser is for https://github.com/xdit-project/xDiT to run CogVideoX with parallel inference\n",
    "# onediff, nexfort is for single gpu acceleration with xdit\n",
    "\n",
    "# Acceleration for Cogvideo # full options are cpu/cu118/cu121/cu124\n",
    "# %pip install --pre torchao --index-url https://download.pytorch.org/whl/nightly/cu124 \n",
    "# %pip install optimum-quanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pillow-simd in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (9.5.0.post2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Faster image processing\n",
    "# %pip uninstall pillow\n",
    "%pip install pillow-simd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For llama3-vision local\n",
    "# %pip install --upgrade transformers>=4.45.0\n",
    "\n",
    "# Transformers conflict with coquitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:            62Gi        15Gi       886Mi       262Mi        46Gi        46Gi\n",
      "Swap:          511Gi       4.6Gi       507Gi\n"
     ]
    }
   ],
   "source": [
    "# See how much memory is available\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                         x86_64\n",
      "CPU op-mode(s):                       32-bit, 64-bit\n",
      "Address sizes:                        39 bits physical, 48 bits virtual\n",
      "Byte Order:                           Little Endian\n",
      "CPU(s):                               24\n",
      "On-line CPU(s) list:                  0-23\n",
      "Vendor ID:                            GenuineIntel\n",
      "Model name:                           12th Gen Intel(R) Core(TM) i9-12900KF\n",
      "CPU family:                           6\n",
      "Model:                                151\n",
      "Thread(s) per core:                   2\n",
      "Core(s) per socket:                   16\n",
      "Socket(s):                            1\n",
      "Stepping:                             2\n",
      "CPU max MHz:                          5200.0000\n",
      "CPU min MHz:                          800.0000\n"
     ]
    }
   ],
   "source": [
    "# Check CPU information\n",
    "!lscpu | head -n 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure GPU works from pytorch\n",
    "\n",
    "If running local models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### GPU VRAM Usage\n",
       "\n",
       "| GPU Index | GPU Name | Used VRAM (GB) | Total VRAM (GB) | VRAM Usage (%) |\n",
       "|-----------|----------|------------------|-------------------|------------------|\n",
       "| 0 | NVIDIA GeForce RTX 4090 | 21.35 GB | 23.64 GB | 90.31%        |\n",
       "| 1 | NVIDIA GeForce RTX 4090 | 21.31 GB | 23.64 GB | 90.14%        |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def show_memory_usage():\n",
    "    # GPU Info\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_table = \"\"\"### GPU VRAM Usage\n",
    "\n",
    "| GPU Index | GPU Name | Used VRAM (GB) | Total VRAM (GB) | VRAM Usage (%) |\n",
    "|-----------|----------|------------------|-------------------|------------------|\n",
    "\"\"\"\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            free, total = torch.cuda.mem_get_info(i)\n",
    "            used = total - free\n",
    "            used_gb = used / 1024 ** 3\n",
    "            total_gb = total / 1024 ** 3\n",
    "            percent_used = used_gb / total_gb * 100.0\n",
    "\n",
    "            gpu_table += f\"| {i} | {gpu_name} | {used_gb:.2f} GB | {total_gb:.2f} GB | {percent_used:.2f}%        |\\n\"\n",
    "\n",
    "        display(Markdown(gpu_table))\n",
    "    else:\n",
    "        display(Markdown(\"**No GPU available**\"))\n",
    "\n",
    "\n",
    "show_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log into Hugging Face\n",
    "\n",
    "So we can pull models! (if running locally)\n",
    "\n",
    "https://huggingface.co/settings/tokens to get a token and set it in `HF_TOKEN` environment variable or do the following in your shell\n",
    "\n",
    "```sh\n",
    "huggingface-cli login\n",
    "```\n",
    "\n",
    "See https://huggingface.co/docs/huggingface_hub/en/quick-start for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e5bbb81b4a4588bd50873ee5491f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text-to-image', 'image-generation', 'flux']\n"
     ]
    }
   ],
   "source": [
    "# Make sure it works by fetching info about a model\n",
    "from huggingface_hub import ModelCard\n",
    "\n",
    "model_card = ModelCard.load('black-forest-labs/FLUX.1-dev')\n",
    "print(model_card.data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flash Attention\n",
    "\n",
    "Ninja will make it build much faster.\n",
    "\n",
    "Per [PyPi](https://pypi.org/project/flash-attn/):\n",
    "\n",
    "> Without ninja, compiling can take a very long time (2h) since it does not use multiple CPU cores. With ninja compiling takes 3-5 minutes on a 64-core machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: packaging in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (24.1)\n",
      "Requirement already satisfied: ninja in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (1.11.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "1.11.1.git.kitware.jobserver-1\n"
     ]
    }
   ],
   "source": [
    "%pip install packaging ninja\n",
    "!ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MAX_JOBS=8\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: flash-attn in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (2.6.3)\n",
      "Requirement already satisfied: torch in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from flash-attn) (2.6.0.dev20241107+cu121)\n",
      "Requirement already satisfied: einops in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: pytorch-triton==3.1.0+cf34004b8a in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (3.1.0+cf34004b8a)\n",
      "Requirement already satisfied: setuptools in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from torch->flash-attn) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/matt/miniconda3/envs/plotomatic/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Adjust MAX_JOBS to suit your machine. I used 8 for 64GB RAM \n",
    "%env MAX_JOBS=8\n",
    "\n",
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIM LLM Microservice Container\n",
    "\n",
    "Run the nemo container locally. We can also use the cloud version by updating `settings.py`.\n",
    "\n",
    "See [https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html](https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html) for more info.\n",
    "\n",
    "```sh\n",
    "echo \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Repository,Latest Tag,Image Size,Updated Date,Permission,Signed Tag?,Access Type,Associated Products\n",
      "CodeLlama-34B-Instruct,nim/meta/codellama-34b-instruct,latest,6.37 GB,\"Oct 07, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n",
      "RFdiffusion,nim/ipd/rfdiffusion,2.0,11.21 GB,\"Oct 30, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Meta/Llama3-70b-instruct,nim/meta/llama3-70b-instruct,1.0.3,5.98 GB,\"Aug 02, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3.1-70b-instruct,nim/meta/llama-3.1-70b-instruct,1.2,6.37 GB,\"Sep 20, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "ASR Parakeet CTC Riva 1.1b,nim/nvidia/parakeet-ctc-1.1b-asr,1.0.0,6.84 GB,\"Aug 06, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3-SQLCoder-8B,nim/defog/llama-3-sqlcoder-8b,latest,6.37 GB,\"Oct 31, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3.1-8b-instruct,nim/meta/llama-3.1-8b-instruct,1.2.2,6.37 GB,\"Oct 01, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "AlphaFold2-Multimer,nim/deepmind/alphafold2-multimer,1.0.0,11.62 GB,\"Oct 07, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "NVIDIA Retrieval QA Mistral 7B Embedding v2,nim/nvidia/nv-embedqa-mistral-7b-v2,1.0.1,7.98 GB,\"Jul 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "NVIDIA Retrieval QA Mistral 4B Reranking v3,nim/nvidia/nv-rerankqa-mistral-4b-v3,1.0.2,7.93 GB,\"Aug 06, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "CodeLlama-70B-Instruct,nim/meta/codellama-70b-instruct,1.2.2,6.37 GB,\"Oct 07, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n",
      "Nemotron-4-340B-Reward,nim/nvidia/nemotron-4-340b-reward,1.2.0,6.37 GB,\"Sep 16, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Phind-CodeLlama-34B-v2-Instruct,nim/phind/phind-codellama-34b-v2-instruct,1.2.3,6.37 GB,\"Oct 30, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n",
      "NV-CLIP,nim/nvidia/nvclip,1.0.0,13.5 GB,\"Oct 03, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Mixtral-8x22B-Instruct-v0.1,nim/mistralai/mixtral-8x22b-instruct-v01,1.2.2,6.37 GB,\"Sep 26, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Mistral-NeMo-Minitron-8B-Instruct,nim/nv-mistralai/mistral-nemo-minitron-8b-8k-instruct,1.2.3,6.37 GB,\"Oct 23, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n",
      "Mistral-Nemo-12B-Instruct,nim/nv-mistralai/mistral-nemo-12b-instruct,1.2,6.37 GB,\"Sep 26, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "TTS FastPitch HifiGAN Riva,nim/nvidia/fastpitch-hifigan-tts,1.0.0,6.84 GB,\"Aug 06, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3.1-8b-base,nim/meta/llama-3.1-8b-base,1.1.2,6.27 GB,\"Aug 21, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Meta/Llama3-8b-instruct,nim/meta/llama3-8b-instruct,1.0.3,5.98 GB,\"Aug 02, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "ProteinMPNN,nim/ipd/proteinmpnn,1,8.97 GB,\"Aug 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "NMT Megatron Riva 1b,nim/nvidia/megatron-1b-nmt,1.0.0,6.84 GB,\"Aug 06, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "MolMIM,nim/nvidia/molmim,1.0.0,13.04 GB,\"Aug 01, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3-Taiwan-70B-Instruct,nim/yentinglin/llama-3-taiwan-70b-instruct,latest,6.27 GB,\"Aug 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Mixtral-8x7B-Instruct-v0.1,nim/mistralai/mixtral-8x7b-instruct-v01,1.2.1,6.37 GB,\"Sep 20, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Snowflake Arctic Embed Large Embedding,nim/snowflake/arctic-embed-l,1.0.1,7.98 GB,\"Jul 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "nemotron-4-340b-instruct,nim/nvidia/nemotron-4-340b-instruct,1.1.2,6.27 GB,\"Aug 29, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "meta-llama-2-70b-chat,nim/meta/llama-2-70b-chat,1.0.3,5.98 GB,\"Aug 21, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3-Swallow-70B-Instruct-v0.1,nim/tokyotech-llm/llama-3-swallow-70b-instruct-v0.1,latest,6.27 GB,\"Aug 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Phi-3-Mini-4K-Instruct,nim/microsoft/phi-3-mini-4k-instruct,1.2.3,6.37 GB,\"Oct 22, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n",
      "Eye Contact,nim/nvidia/maxine-eye-contact,1.0.0,15.66 GB,\"Oct 09, 2024\",unlocked,True,LISTED,nv-ai-enterprise\n",
      "NVIDIA Retrieval QA E5 Embedding v5,nim/nvidia/nv-embedqa-e5-v5,1.1.0,5.28 GB,\"Oct 25, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Llama-3.1-405b-instruct,nim/meta/llama-3.1-405b-instruct,1.2.0,6.37 GB,\"Sep 11, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Mistral-7B-Instruct-v0.3,nim/mistralai/mistral-7b-instruct-v0.3,latest,6.27 GB,\"Sep 10, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "meta-llama-2-7b-chat,nim/meta/llama-2-7b-chat,1.0.3,5.98 GB,\"Aug 21, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "meta-llama-2-13b-chat,nim/meta/llama-2-13b-chat,1.0.3,5.98 GB,\"Aug 21, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "DiffDock,nim/mit/diffdock,2,12.84 GB,\"Oct 29, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "AlphaFold2,nim/deepmind/alphafold2,1.0.0,11.6 GB,\"Aug 27, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "CodeLlama-13B-Instruct,nim/meta/codellama-13b-instruct,1.2.2,6.37 GB,\"Oct 07, 2024\",unlocked,True,LISTED,\"nv-ai-enterprise, nim-dev\"\n"
     ]
    }
   ],
   "source": [
    "!ngc registry image list --format_type csv nvcr.io/nim/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemotron-4-340B-Reward,nim/nvidia/nemotron-4-340b-reward,1.2.0,6.37 GB,\"Sep 16, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "nemotron-4-340b-instruct,nim/nvidia/nemotron-4-340b-instruct,1.1.2,6.27 GB,\"Aug 29, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n"
     ]
    }
   ],
   "source": [
    "!ngc registry image list --format_type csv nvcr.io/nim/* | grep nemotron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rats! No nemotron 70b available. Llama will have to do for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta/Llama3-8b-instruct,nim/meta/llama3-8b-instruct,1.0.3,5.98 GB,\"Aug 02, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n",
      "Meta/Llama3-70b-instruct,nim/meta/llama3-70b-instruct,1.0.3,5.98 GB,\"Aug 02, 2024\",unlocked,True,LISTED,\"nim-dev, nv-ai-enterprise\"\n"
     ]
    }
   ],
   "source": [
    "!ngc registry image list --format_type csv nvcr.io/nim/* | grep llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "ngc registry image list --format_type ascii\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```sh\n",
    "REPO=nim/meta/llama3-8b-instruct\n",
    "TAG=1.2.1\n",
    "\n",
    "ngc registry image info --format_type ascii ${REPO}:${TAG}\n",
    "\n",
    "export LOCAL_NIM_CACHE=~/.cache/nim\n",
    "export IMG_NAME=\"nvcr.io/${REPO}:${TAG}\"\n",
    "\n",
    "# docker pull nvcr.io/nvidia/nemo:24.05.llama3.1\n",
    "docker pull IMG_NAME\n",
    "\n",
    "docker run -d -it --rm \\\n",
    "  --name=nim \\\n",
    "  --runtime=nvidia \\\n",
    "  --gpus all \\\n",
    "  --shm-size=16GB \\\n",
    "  -e NGC_API_KEY=$NGC_API_KEY \\\n",
    "  -v \"$LOCAL_NIM_CACHE:/opt/nim/.cache\" \\\n",
    "  -u $(id -u) \\\n",
    "  -p 8000:8000 \\\n",
    "  $IMG_NAME\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "Onto [Step 1: Story Prompt](./1_story_prompt.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotomatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
